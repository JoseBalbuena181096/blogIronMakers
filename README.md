# üöÄ Sistema Iron Makers

Bienvenido a la documentaci√≥n oficial del **Sistema Iron Makers**. Esta plataforma es un ecosistema educativo avanzado que fusiona un frontend moderno (Next.js) con un backend de Inteligencia Artificial (FastAPI + LangChain).

El sistema no solo entrega contenido educativo, sino que act√∫a como un tutor personalizado que entiende el contexto del estudiante, modera el contenido por seguridad y asiste en tareas de programaci√≥n compleja.

---

## üé• Demo del Funcionamiento

[![Sistema Iron Makers Demo](https://img.youtube.com/vi/vcGux2oKRWc/0.jpg)](https://www.youtube.com/watch?v=vcGux2oKRWc)

*Haz clic en la imagen para ver el video de demostraci√≥n.*

---

## üìö √çndice

1. [Arquitectura Global](#-arquitectura-global)
2. [Flujo de Datos & Interacci√≥n](#-flujo-de-datos--interacci√≥n)
3. [Componentes del Sistema](#-componentes-del-sistema)
    - [Frontend (Blog Educativo)](#frontend-blog-educativo)
    - [Backend (IA & L√≥gica)](#backend-ia--l√≥gica)
4. [Deep Dive: Arquitectura de IA](#-deep-dive-arquitectura-de-ia-backend)
    - [El Grafo (LangGraph)](#1-el-grafo-langgraph)
    - [Sistema de Ruteo (Supervisor)](#2-sistema-de-ruteo-supervisor)
    - [Agentes Especializados](#3-agentes-especializados)
    - [Pipeline RAG (Contexto)](#4-pipeline-rag-contexto)
5. [Gu√≠a de Instalaci√≥n Local](#-gu√≠a-de-instalaci√≥n-local)
6. [Gu√≠a de Despliegue (Producci√≥n)](#-gu√≠a-de-despliegue-producci√≥n)

---

## üèõ Arquitectura Global

El sistema opera bajo una arquitectura de **Microservicios H√≠bridos**. El frontend es est√°tico/ISR (Incremental Static Regeneration) optimizado para rapidez, mientras que el backend es un servicio API RESTful din√°mico que mantiene estado conversacional a trav√©s de grafos de LangChain (LangGraph).

```mermaid
graph TB
    subgraph Client [Cliente]
        Browser[Navegador Usuario]
    end

    subgraph Cloud_Infrastructure [Infraestructura Cloud]
        direction TB
        
        subgraph Vercel_Frontend ["Vercel (Frontend)"]
            NextApp[Next.js App Router]
            AuthPages[Auth Pages]
            Dashboard[Dashboard Estudiante]
        end
        
        subgraph Railway_Backend ["Railway (Backend IA)"]
            FastAPI[FastAPI Gateway]
            
            subgraph AI_Engine ["Motor de IA (LangGraph)"]
                Supervisor[Supervisor Agent]
                Coder[Programming Agent]
                Tutor[Socratic Tutor]
                Mod[Safety Guard]
            end
            
            Services[Servicios: Gmail, Resend, PDF]
        end
        
        subgraph Data_Layer ["Supabase (Datos & Auth)"]
            Auth[Auth Service]
            Postgres[(PostgreSQL + pgvector)]
            Buckets[File Storage]
        end
        
        subgraph External_AI [Modelos LLM]
            GPT4[OpenAI GPT-4o]
            Gemini[Google Gemini 1.5]
        end
    end

    Browser -->|HTTPS| NextApp
    Browser -->|Websockets/HTTP| FastAPI
    
    NextApp -->|Auth/Data| Data_Layer
    FastAPI -->|Valida Token| Data_Layer
    FastAPI -->|Inferencia| External_AI
    
    Supervisor -->|Planifica| AI_Engine
    AI_Engine -->|Tools| Services
```

---

## üîÑ Flujo de Datos & Interacci√≥n

### ¬øC√≥mo interact√∫a el Frontend con el Backend?

El Frontend no "piensa", solo presenta. Cuando un usuario hace una pregunta compleja en el chat:

1.  **Frontend**: Captura el input del usuario y lo env√≠a al endpoint `/chat` del Backend.
2.  **Backend (FastAPI)**: Recibe la solicitud, valida la identidad del usuario con Supabase Auth.
3.  **Supervisor (LangGraph)**: Analiza la intenci√≥n. ¬øEs una duda de c√≥digo? ¬øEs una pregunta conceptual?
4.  **Enrutamiento**:
    *   Si es c√≥digo -> Activa **Programming Agent**.
    *   Si es concepto -> Activa **Socratic Tutor**.
    *   Si es peligroso -> Activa **Safety System**.
5.  **Respuesta**: El agente genera una respuesta (streaming) que FastAPI devuelve al Frontend en tiempo real.

```mermaid
sequenceDiagram
    participant U as Usuario
    participant FE as Frontend (Next.js)
    participant BE as Backend (FastAPI)
    participant S as Supervisor (IA)
    participant DB as Supabase
    
    U->>FE: Env√≠a pregunta: "¬øC√≥mo funciona un `for` loop?"
    FE->>BE: POST /api/chat {message, user_id}
    BE->>DB: Verificar Token & Obtener Historial
    DB-->>BE: Perfil de Usuario + Historial
    
    BE->>S: Inyectar Contexto + Pregunta
    S->>S: Analizar Intenci√≥n...
    
    rect rgb(200, 220, 240)
        Note over S: Decisi√≥n: Nivel Principiante -> Tutor Socr√°tico
        S->>TutorAgent: Invocar Agente Tutor
        TutorAgent->>TutorAgent: Generar explicaci√≥n guiada
        TutorAgent-->>BE: Respuesta Streaming
    end
    
    BE-->>FE: Stream de Respuesta (Tokens)
    FE-->>U: Muestra respuesta letra por letra
```

---

## üß© Componentes del Sistema

### Frontend: Blog Educativo (`/blog`)

Construido con las √∫ltimas tecnolog√≠as para garantizar rendimiento y SEO.

*   **Next.js 16**: Utiliza Server Components para renderizar el blog super r√°pido.
*   **Supabase Client**: Maneja la sesi√≥n del usuario (Login con Google/GitHub m√°gico).
*   **Mermaid.js & KateX**: Renderiza diagramas y ecuaciones matem√°ticas en tiempo real dentro del chat y los art√≠culos.

### Backend: IA & L√≥gica (`/backend_python_ia`)

El cerebro real. No es solo una API CRUD.

*   **FastAPI**: Maneja las conexiones HTTP y Websockets de baja latencia.
*   **LangGraph**: Permite crear flujos de conversaci√≥n c√≠clicos (Loop: Pensar -> Actuar -> Observar -> Responder).
*   **Servicios**: M√≥dulos aislados para enviar correos (Gmail/Resend) o procesar archivos (PDFPlumber).

---

## üß† Deep Dive: Arquitectura de IA (Backend)

Aqu√≠ es donde ocurre la magia. El sistema no utiliza una sola cadena de "Prompt Engineering", sino una **M√°quina de Estados Finita (State Graph)** orquestada por `LangGraph`.

### 1. El Grafo (LangGraph)

El grafo define el ciclo de vida de cada mensaje del usuario.

```mermaid
stateDiagram-v2
    [*] --> Moderation: Input Usuario
    
    state Moderation {
        [*] --> CheckSafety
        CheckSafety --> Blocked: T√≥xico?
        CheckSafety --> Retrieval: Seguro?
    }
    
    state Retrieval {
        [*] --> SearchVectors: Busca en Supabase
        SearchVectors --> InjectContext: A√±ade al State
    }
    
    state Supervisor {
        [*] --> AnalyzeIntent: LLM Decision
        AnalyzeIntent --> ProgrammingAgent: C√≥digo
        AnalyzeIntent --> TutoringAgent: Conceptos
        AnalyzeIntent --> EmailAgent: Ayuda Humana
    }
    
    Retrieval --> Supervisor
    
    ProgrammingAgent --> [*]: Responde
    TutoringAgent --> [*]: Responde
    
    state EmailAgent {
        [*] --> CallTool: notify_instructor()
        CallTool --> [*]: Confirma Env√≠o
    }
    
    Blocked --> [*]: Mensaje de Error
```

**Explicaci√≥n de Nodos:**
*   `Moderation`: Utiliza OpenAI moderations API + filtros personalizados para detectar grooming, suicidio o violencia antes de procesar nada.
*   `Retrieve`: Realiza una b√∫squeda sem√°ntica (Embeddings) en Supabase para encontrar documentos PDF/Clases relevantes a la pregunta.
*   `Supervisor`: Decide qui√©n atiende la consulta.

### 2. Sistema de Ruteo (Supervisor)

Ubicado en `app/core/supervisor_agent.py`, utiliza un Prompt de Sistema Clasificador.

*   **Input**: *"Mi c√≥digo Python tira error en la l√≠nea 5"*
*   **L√≥gica**:
    1.  Extrae texto (si hay im√°genes).
    2.  Ejecuta `route_by_llm`: Un LLM peque√±o clasifica la intenci√≥n en `PROGRAMMING`, `TUTORING` o `EMAIL`.
    3.  Devuelve el siguiente nodo del grafo.

### 3. Agentes Especializados

Cada agente tiene una "Personalidad" instanciada un prompt de sistema √∫nico y acceso a herramientas espec√≠ficas.

#### A. Programming Agent (`app/agents/programming_agent.py`)
*   **Prompt**: "Eres un experto en Python, C++ y Arduino. Tu objetivo es hacer debugging y explicar errores."
*   **Comportamiento**: Analiza stack traces, sugiere correcciones de sintaxis y da ejemplos de c√≥digo. NO da solo la soluci√≥n, explica el *por qu√©*.

#### B. Socratic Tutor (`app/agents/tutoring_agent.py`)
*   **Prompt**: "Eres un educador Socr√°tico. NO des la respuesta directa. Gu√≠a al estudiante con preguntas."
*   **Adaptabilidad**: Ajusta su vocabulario basado en la edad del usuario (extra√≠da de Supabase).

#### C. Email Agent (`app/agents/email_agent.py`)
*   **Funci√≥n**: Puente con humanos.
*   **Herramientas**: Tiene acceso exclusivo a `notify_instructor`.
*   **Trigger**: Se activa si el usuario dice "Necesito ayuda humana" o "Contacta al profesor".

### 4. Pipeline RAG (Contexto)

El sistema utiliza **RAG (Retrieval-Augmented Generation)** para que la IA sepa sobre el contenido del curso.

1.  **Ingesta**: Los documentos del curso se dividen en chunks y se vectorizan (OpenAI Embeddings).
2.  **Almacenamiento**: Se guardan en Supabase (`pgvector`).
3.  **Consulta**:
    *   En el nodo `retrieve`, la pregunta del usuario se vectoriza.
    *   Se hace una b√∫squeda de similitud coseno en Supabase (`match_documents` RPC).
    *   Los chunks m√°s relevantes se inyectan en el `AgentState` bajo la clave `context`.

---

## üõ† Gu√≠a de Instalaci√≥n Local

### Prerrequisitos
*   Node.js 18+
*   Python 3.10+
*   Cuenta en Supabase y OpenAI/Google AI.

### Paso 1: Configurar Backend (Puerto 8000)

1.  Entra a la carpeta: `cd backend_python_ia`
2.  Crea entorno virtual:
    ```bash
    python -m venv venv
    source venv/bin/activate  # (Windows: venv\Scripts\activate)
    ```
3.  Instala librer√≠as: `pip install -r requirements.txt`
4.  Crea `.env` con tus llaves:
    ```env
    OPENAI_API_KEY=sk-...
    SUPABASE_URL=https://xyz.supabase.co
    SUPABASE_KEY=ey...
    ```
5.  Corre el servidor: `uvicorn main:app --reload`

### Paso 2: Configurar Frontend (Puerto 3000)

1.  Entra a la carpeta: `cd blog`
2.  Instala dependencias: `npm install`
3.  Crea `.env.local`:
    ```env
    NEXT_PUBLIC_SUPABASE_URL=...
    NEXT_PUBLIC_SUPABASE_ANON_KEY=...
    NEXT_PUBLIC_API_URL=http://localhost:8000
    ```
4.  Corre la app: `npm run dev`

---

## üöÄ Gu√≠a de Despliegue (Producci√≥n)

### Desplegar Backend en Railway üöÇ

1.  Sube tu repo a GitHub.
2.  Importa el repo en Railway.
3.  Configura el **Root Directory** en `/backend_python_ia`.
4.  Configura el **Start Command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`.
5.  Variables clave: `OPENAI_API_KEY`, `SUPABASE_URL`, `GMAIL_CREDENTIALS_JSON`.

### Desplegar Frontend en Vercel ‚ñ≤

1.  Importa el repo en Vercel.
2.  **Framework Preset**: Next.js.
3.  **Root Directory**: `blog`.
4.  Variables: `NEXT_PUBLIC_SUPABASE_URL`, `NEXT_PUBLIC_API_URL` (URL de Railway).
5.  Deploy.

---

## üë®‚Äçüíª Autor

Este proyecto fue creado y es mantenido por:

**Jos√© √Ångel Balbuena Palma**  
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/jose-angel-balbuena-palma-52279a177/)

---

**Sistema Iron Makers** v4.0 - Documentaci√≥n T√©cnica Avanzada.
